fvfm
fvfm <- ggplot(data = fire.data,aes(x= depth, y=Fv/Fm, fill=Species))+
geom_boxplot() +
theme_set(theme_cowplot()) +
labs(title="Quantum yield of photochemistry in PSII", y= "Fv’/Fm’") +
theme(legend.position = "none") +
theme(axis.title.y = element_blank()) +
#  scale_fill_manual(values=c("#4393C3","#F4A582")) +
scale_x_discrete(limits = rev) +
coord_flip()
fvfm
sigma <- ggplot(data = fire.data,aes(x= depth, y=Sigma, fill=Species))+
geom_boxplot() +
theme_set(theme_cowplot()) +
labs(title="Functional absorption cross-section of PSII", y= "σPSII’(A2)") +
theme(legend.position = "none") +
theme(axis.title.y = element_blank()) +
#  scale_fill_manual(values=c("#4393C3","#F4A582")) +
scale_x_discrete(limits = rev) +
coord_flip()
sigma
pmax <- ggplot(data = fire.data,aes(x= depth, y=Pmax.e.s, fill=Species))+
geom_boxplot() +
theme_set(theme_cowplot()) +
labs(title="Maximum photosynthetic rate ", y="Pmax (electron s-1 PSII-1)") +
theme(legend.position = "none") +
theme(axis.title.y = element_blank()) +
#  scale_fill_manual(values=c("#4393C3","#F4A582")) +
scale_x_discrete(limits = rev) +
coord_flip()
pmax
p <- ggplot(data = fire.data,aes(x= depth, y=p, fill=Species))+
geom_boxplot() +
theme_set(theme_cowplot()) +
labs(title="connectivity parameter ", y="p") +
theme(legend.position = "none") +
theme(axis.title.y = element_blank()) +
#scale_fill_manual(values=c("#4393C3","#F4A582")) +
scale_x_discrete(limits = rev) +
coord_flip()
p
p_legend <- ggplot(data = fire.data,aes(x= depth, y=p, fill=Species))+
geom_boxplot() +
theme_set(theme_cowplot()) +
labs(title="p") +
#  scale_fill_manual(values=c("#4393C3","#F4A582")) +
coord_flip()
p_legend
nolegend <- plot_grid(fvfm,sigma,pmax, p, labels = c('a','b','c','d'))
legend <- get_legend(p_legend)
fire_plot <- plot_grid(nolegend,legend, rel_widths = c(1,0.25))
fire_plot
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, message = FALSE, warning = FALSE)
#Read in required libraries
library("devtools")
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("lubridate")
library("chron")
library("plyr")
library("dplyr")
library("tidyr")
library("tidyverse")
library("broom")
library("ggpubr")
library("minpack.lm")
library("ggpmisc")
Data <-read.csv("/Users/talimass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel/PAM/11062024_plate1.csv", header=T, sep=";", na.string="NA") #reads in the data files
Data <- Data[, c("Date", "Time", "PAR", "ETR1","ETR2","ETR3","ETR4","ETR5","ETR6","ETR7","ETR8","ETR9","ETR10","ETR11","ETR12","ETR13","ETR14","ETR15","ETR16")]
# change format from wide to long
Data <- Data %>%  pivot_longer(., cols = starts_with("ETR"), names_to = "Spat.ID")
Data$value <- na_if(Data$value, 0)
#need to Remove all data at PAR values above where ETR hits zero
Data$PAR <- as.numeric(Data$PAR)
colnames(Data)[5] ="ETR"
Data <- Data %>%
subset(ETR<40)
Data %>%
ggplot(aes(x=PAR, y=ETR, color=Spat.ID))+
geom_point()+
geom_line()+
facet_wrap("Spat.ID")+
theme_bw()
#Data <- Data %>%
#filter(!Spat.ID=="ETR1"& !Spat.ID=="ETR3"& !Spat.ID=="ETR5" & !Spat.ID=="ETR7"& !Spat.ID=="ETR8" & !Spat.ID=="ETR10"& !Spat.ID=="ETR11" & !Spat.ID=="ETR12"& !Spat.ID=="ETR13" & !Spat.ID=="ETR14"& !Spat.ID=="ETR15")
Data %>%
ggplot(aes(x=PAR, y=ETR, color=Spat.ID))+
geom_point()+
geom_line()+
facet_wrap("Spat.ID")+
theme_bw()
set.seed(123)
Data.PI <- Data %>% subset(PAR<500)
curve.nlsPIC <- Data.PI %>% nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4))
coef(curve.nlsPIC)
plot(ETR ~ PAR, data = Data.PI)
lines(0:900,
predict(curve.nlsPIC,
newdata = data.frame(PAR = 0:900)))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR2"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR1"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR3"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR5"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR7"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR8"))
nls_data1 <- Data.PI %>%
group_by(Spat.ID) %>%
nest(-Spat.ID) %>%
mutate(model1 = map(data, ~
nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4)) %>%
tidy %>%
dplyr::select(term, estimate) %>%
spread(term, estimate))) %>%
unnest(model1) %>%
mutate(Ik = Am/AQY)%>%
mutate(Date = "20240611") %>%
mutate(Plate = "Plate1") %>%
mutate(Spat.ID.PAM = paste0(Date,"_",Plate,"_",Spat.ID))
write_csv(nls_data1, "/Users/talimass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/output/1106_1_liel_pi_curve_pars_NLS_fixedparms.csv")
augmented <- Data.PI %>%
filter(PAR <650) %>%
nest(-Spat.ID) %>%
mutate(
fit = map(data, ~ nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4))),
augmented = map(fit, augment),
) %>%
unnest(augmented)
augmented$ID <-augmented$Spat.ID
Aug <- augmented %>% separate(ID, c("Sp", "Num", "Type"))
#all colonies together
pdf("/Users/talimass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/output/1106_Plate1_PI_Curve_Fit_Plots.pdf")
PI.curves <- Aug %>%
ggplot(aes(x=PAR, y=ETR, color=Spat.ID))+
geom_point() +
geom_line(aes(y=.fitted, x=PAR,group=Spat.ID))+
theme_classic()+
labs(x = expression(paste('PAR (', mu, "mol photons m"^-2, 's'^-1,")")),
y = expression(paste("ETR")))+
theme(legend.position = "top")
PI.curves
dev.off()
Data <-read.csv("/Users/talimass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel/PAM/11062024_plate2.csv", header=T, sep=";", na.string="NA") #reads in the data files
Data <- Data[, c("Date", "Time", "PAR", "ETR1","ETR2","ETR3","ETR4","ETR5","ETR6","ETR7","ETR8","ETR9","ETR10","ETR11","ETR12","ETR13","ETR14","ETR15","ETR16", "ETR17","ETR18","ETR19")]
# change format from wide to long
Data <- Data %>%  pivot_longer(., cols = starts_with("ETR"), names_to = "Spat.ID")
Data$value <- na_if(Data$value, 0)
#need to Remove all data at PAR values above where ETR hits zero
Data$PAR <- as.numeric(Data$PAR)
colnames(Data)[5] ="ETR"
Data <- Data %>%
subset(ETR<40)
Data %>%
ggplot(aes(x=PAR, y=ETR, color=Spat.ID))+
geom_point()+
geom_line()+
facet_wrap("Spat.ID")+
theme_bw()
#Data <- Data %>%
#filter(!Spat.ID=="ETR1"& !Spat.ID=="ETR3"& !Spat.ID=="ETR4"& !Spat.ID=="ETR5" & !Spat.ID=="ETR6"& !Spat.ID=="ETR9" & !Spat.ID=="ETR10"& !Spat.ID=="ETR14" & !Spat.ID=="ETR15"& !Spat.ID=="ETR16" & !Spat.ID=="ETR21"& !Spat.ID=="ETR25" & !Spat.ID=="ETR27"& !Spat.ID=="ETR30")
Data %>%
ggplot(aes(x=PAR, y=ETR, color=Spat.ID))+
geom_point()+
geom_line()+
facet_wrap("Spat.ID")+
theme_bw()
set.seed(123)
Data.PI <- Data %>% subset(PAR<500)
curve.nlsPIC <- Data.PI %>% nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4))
coef(curve.nlsPIC)
plot(ETR ~ PAR, data = Data.PI)
lines(0:900,
predict(curve.nlsPIC,
newdata = data.frame(PAR = 0:900)))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR2"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR5"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR13"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR9"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR31"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR8"))
nls_data1 <- Data.PI %>%
group_by(Spat.ID) %>%
nest(-Spat.ID) %>%
mutate(model1 = map(data, ~
nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4)) %>%
tidy %>%
dplyr::select(term, estimate) %>%
spread(term, estimate))) %>%
unnest(model1) %>%
mutate(Ik = Am/AQY)%>%
mutate(Date = "20240611") %>%
mutate(Plate = "Plate2") %>%
mutate(Spat.ID.PAM = paste0(Date,"_",Plate,"_",Spat.ID))
write_csv(nls_data1, "/Users/talimass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/output/1106_2_liel_pi_curve_pars_NLS_fixedparms.csv")
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR2"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR5"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR13"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR9"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR31"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR8"))
nls_data1 <- Data.PI %>%
group_by(Spat.ID) %>%
nest(-Spat.ID) %>%
mutate(model1 = map(data, ~
nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4)) %>%
tidy %>%
dplyr::select(term, estimate) %>%
spread(term, estimate))) %>%
unnest(model1) %>%
mutate(Ik = Am/AQY)%>%
mutate(Date = "20240611") %>%
mutate(Plate = "Plate2") %>%
mutate(Spat.ID.PAM = paste0(Date,"_",Plate,"_",Spat.ID))
write_csv(nls_data1, "/Users/talimass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/output/1106_2_liel_pi_curve_pars_NLS_fixedparms.csv")
Data <-read.csv("/Users/talimass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel/PAM/11062024_plate2.csv", header=T, sep=";", na.string="NA") #reads in the data files
Data <- Data[, c("Date", "Time", "PAR", "ETR1","ETR2","ETR3","ETR4","ETR5","ETR6","ETR7","ETR8","ETR9","ETR10","ETR11","ETR12","ETR13","ETR14","ETR15","ETR16", "ETR17","ETR18","ETR19")]
# change format from wide to long
Data <- Data %>%  pivot_longer(., cols = starts_with("ETR"), names_to = "Spat.ID")
Data$value <- na_if(Data$value, 0)
#need to Remove all data at PAR values above where ETR hits zero
Data$PAR <- as.numeric(Data$PAR)
colnames(Data)[5] ="ETR"
Data <- Data %>%
subset(ETR<40)
Data %>%
ggplot(aes(x=PAR, y=ETR, color=Spat.ID))+
geom_point()+
geom_line()+
facet_wrap("Spat.ID")+
theme_bw()
#Data <- Data %>%
#filter(!Spat.ID=="ETR1"& !Spat.ID=="ETR3"& !Spat.ID=="ETR4"& !Spat.ID=="ETR5" & !Spat.ID=="ETR6"& !Spat.ID=="ETR9" & !Spat.ID=="ETR10"& !Spat.ID=="ETR14" & !Spat.ID=="ETR15"& !Spat.ID=="ETR16" & !Spat.ID=="ETR21"& !Spat.ID=="ETR25" & !Spat.ID=="ETR27"& !Spat.ID=="ETR30")
Data %>%
ggplot(aes(x=PAR, y=ETR, color=Spat.ID))+
geom_point()+
geom_line()+
facet_wrap("Spat.ID")+
theme_bw()
set.seed(123)
Data.PI <- Data %>% subset(PAR<500)
curve.nlsPIC <- Data.PI %>% nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4))
coef(curve.nlsPIC)
plot(ETR ~ PAR, data = Data.PI)
lines(0:900,
predict(curve.nlsPIC,
newdata = data.frame(PAR = 0:900)))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR2"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR5"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR13"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR9"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR31"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR8"))
nls_data1 <- Data.PI %>%
group_by(Spat.ID) %>%
nest(-Spat.ID) %>%
mutate(model1 = map(data, ~
nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4)) %>%
tidy %>%
dplyr::select(term, estimate) %>%
spread(term, estimate))) %>%
unnest(model1) %>%
mutate(Ik = Am/AQY)%>%
mutate(Date = "20240611") %>%
mutate(Plate = "Plate2") %>%
mutate(Spat.ID.PAM = paste0(Date,"_",Plate,"_",Spat.ID))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR2"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR5"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR13"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR9"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR31"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR8"))
nls_data1 <- Data.PI %>%
group_by(Spat.ID) %>%
nest(-Spat.ID) %>%
mutate(model1 = map(data, ~
nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4)) %>%
tidy %>%
dplyr::select(term, estimate) %>%
spread(term, estimate))) %>%
unnest(model1) %>%
mutate(Ik = Am/AQY)%>%
mutate(Date = "20240611") %>%
mutate(Plate = "Plate2") %>%
mutate(Spat.ID.PAM = paste0(Date,"_",Plate,"_",Spat.ID))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR2"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR5"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR13"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR9"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR31"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR8"))
nls_data1 <- Data.PI %>%
group_by(Spat.ID) %>%
nest(-Spat.ID) %>%
mutate(model1 = map(data, ~
nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4)) %>%
tidy %>%
dplyr::select(term, estimate) %>%
spread(term, estimate))) %>%
unnest(model1) %>%
mutate(Ik = Am/AQY)%>%
mutate(Date = "20240611") %>%
mutate(Plate = "Plate2") %>%
mutate(Spat.ID.PAM = paste0(Date,"_",Plate,"_",Spat.ID))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR2"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR5"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR13"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR9"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR31"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR8"))
nls_data1 <- Data.PI %>%
group_by(Spat.ID) %>%
nest(-Spat.ID) %>%
mutate(model1 = map(data, ~
nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4)) %>%
tidy %>%
dplyr::select(term, estimate) %>%
spread(term, estimate))) %>%
unnest(model1) %>%
mutate(Ik = Am/AQY)%>%
mutate(Date = "20240611") %>%
mutate(Plate = "Plate2") %>%
mutate(Spat.ID.PAM = paste0(Date,"_",Plate,"_",Spat.ID))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR2"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR5"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR13"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR9"))
#Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR31"))
Data.PI <- Data.PI %>% subset(Spat.ID!=("ETR8"))
nls_data1 <- Data.PI %>%
group_by(Spat.ID) %>%
nest(-Spat.ID) %>%
mutate(model1 = map(data, ~
nls(ETR ~ (Am*((AQY*PAR)/(sqrt(Am^2 + (AQY*PAR)^2)))-Rd), data=., start=list(Am=0.7,  AQY=0.001, Rd=.4)) %>%
tidy %>%
dplyr::select(term, estimate) %>%
spread(term, estimate))) %>%
unnest(model1) %>%
mutate(Ik = Am/AQY)%>%
mutate(Date = "20240611") %>%
mutate(Plate = "Plate2") %>%
mutate(Spat.ID.PAM = paste0(Date,"_",Plate,"_",Spat.ID))
write_csv(nls_data1, "/Users/talimass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/output/1106_2_liel_pi_curve_pars_NLS_fixedparms.csv")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
library(devtools)
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
if ("stringr" %in% rownames(installed.packages()) == 'FALSE') install.packages('stringr')
if ("Rmisc" %in% rownames(installed.packages()) == 'FALSE') install.packages('Rmisc')
#load packages
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
library('stringr')
library('Rmisc')
library("ggpmisc")
path.p<-"/Users/talimass/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel_fluoro/Respiration/plates" #location of files
# bring in the respiration file names
file.names<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
#generate a 6 column dataframe with specific column names
#respiration
Resp.R <- data.frame(matrix(NA, ncol=6))
colnames(Resp.R) <- c("Date", "Run", "Sample.ID","Chamber.ID","Intercept", "umol.L.min")
Resp.Rb <- data.frame(matrix(NA, ncol=6))
colnames(Resp.Rb) <- c("Date", "Run", "Sample.ID","Chamber.ID","Intercept", "umol.L.min")
Sample.Info<-read.csv("/Users/talimass/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel_fluoro/Respiration/Spat_Info.csv") #information on life stage, number of individuals, runs, etc.
rename <- Sample.Info$Chamber.ID
samp <- Sample.Info$Sample.ID
run <- str_sub(file.names, 10, 15) #grab run from file name
date <- str_sub(file.names, 1, str_length(file.names)-16) #grab date from file name
#load in respiration start times as a list the same length as the number of files
starttimes<-read.csv("/Users/talimass/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel_fluoro/Respiration/starttimes.csv") #read in file of starting R and P phase times
rtime<-starttimes$Rtime #list respiration start times. For respiration measurements, filter as > than this time
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), skip = 56, header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Temp <- Resp.Data[,31] #assigns temp column
Resp.Data$Time.Min <- seq.int(from=0, to=((nrow(Resp.Data)*0.25)-0.25), by = 0.25) #set time in min
Resp.Data <- Resp.Data %>% #filters data by phase (respiration only)
filter(Time.Min > rtime[i])
Resp.Data.N <- Resp.Data[,3:26] #subset desired columns
for(j in 1:(ncol(Resp.Data.N))){
model <- rankLocReg(
xall=Resp.Data$Time.Min, yall=as.numeric(Resp.Data.N[, j]),
alpha=0.4, method="pc", verbose=TRUE) #extract slopes, percentile rank method with minimum window size of 0.4. This means that in order to fit a slope, it has to encompass at least 40% of available datapoints.
pdf(paste0("/Users/talimass/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel_fluoro/Respiration/RespirationPlots /",date[i], "_",run[i],"_",rename[j],"_regression_trunc.pdf")) #generate output file names
plot(model)
dev.off()
Resp.Rb[j,1] <- as.character(date[i]) #stores the date
Resp.Rb[j,2] <- as.character(run[i]) #stores the run number
Resp.Rb[j,3] <- as.character(samp[j+(i-1)*ncol(Resp.Data.N)]) #stores the sample ID
Resp.Rb[j,4] <- as.character(rename[j]) #stores the chamber ID
Resp.Rb[j,5:6] <- model$allRegs[i,c(4,5)] #inserts slope and intercept in the dataframe
}
Resp.R <- rbind(Resp.R, Resp.Rb) #bind final data frame
}
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), skip = 56, header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Temp <- Resp.Data[,31] #assigns temp column
Resp.Data$Time.Min <- seq.int(from=0, to=((nrow(Resp.Data)*0.25)-0.25), by = 0.25) #set time in min
Resp.Data <- Resp.Data %>% #filters data by phase (respiration only)
filter(Time.Min > rtime[i])
Resp.Data.N <- Resp.Data[,3:26] #subset desired columns
for(j in 1:(ncol(Resp.Data.N))){
model <- rankLocReg(
xall=Resp.Data$Time.Min, yall=as.numeric(Resp.Data.N[, j]),
alpha=0.4, method="pc", verbose=TRUE) #extract slopes, percentile rank method with minimum window size of 0.4. This means that in order to fit a slope, it has to encompass at least 40% of available datapoints.
pdf(paste0("/Users/talimass/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel_fluoro/Respiration/RespirationPlots /",date[i], "_",run[i],"_",rename[j],"_regression_trunc.pdf")) #generate output file names
plot(model)
dev.off()
Resp.Rb[j,1] <- as.character(date[i]) #stores the date
Resp.Rb[j,2] <- as.character(run[i]) #stores the run number
Resp.Rb[j,3] <- as.character(samp[j+(i-1)*ncol(Resp.Data.N)]) #stores the sample ID
Resp.Rb[j,4] <- as.character(rename[j]) #stores the chamber ID
Resp.Rb[j,5:6] <- model$allRegs[i,c(4,5)] #inserts slope and intercept in the dataframe
}
Resp.R <- rbind(Resp.R, Resp.Rb) #bind final data frame
}
Resp.R <- Resp.R[-1,] #remove empty column
write.csv(Resp.R, paste0("/Users/talimass/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel_fluoro/Respiration/Respiration_rates_Spis_2024.csv", sep="")) #save respiration rate data
Resp.Rates <- read.csv(file = "/Users/talimass/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/data/Liel_fluoro/Respiration/Respiration_rates_Spis_2024.csv") #read file back in so slopes don't have to be generated every time
Resp.Rates <- subset(Resp.Rates, select = -c(X) ) #remove empty column
#format "Date" column
Resp.Rates$Date <- gsub("_.*", "", Resp.Rates$Date)
Resp.Rates$Date <- as.numeric(as.character(Resp.Rates$Date))
#format "run" column
#Resp.Rates<-Resp.Rates %>%
#  mutate(Run = str_sub(Run, 4, -1))
#Resp.Rates$Run<-as.integer(Resp.Rates$Run) #format as # rather than run #, set as integer
oxygen<-left_join(Sample.Info, Resp.Rates, by="Sample.ID") #add respiration data
colnames(oxygen)[colnames(oxygen) == 'Intercept'] <- 'Resp.Intercept' #rename to specify R
colnames(oxygen)[colnames(oxygen) == 'umol.L.min'] <- 'R.umol.L.min' #rename to specify R
ggplot(oxygen, aes(R.umol.L.min, Plate.ID,)) +
geom_point()
#Account for chamber volume to convert from umol L-1 m-1 to umol m-1. This standardizes across water volumes (different because of coral size) and removes per Liter
oxygen$R.umol.min <- oxygen$R.umol.L.min * oxygen$Volume #calculate
ggplot(oxygen, aes(R.umol.min, Plate.ID,)) +
geom_point()
blank_data <- subset(oxygen, Type == "Blank") #subset to blank data only
plot(blank_data$R.umol.min,  ylab="umol O2 min-1") #blanks during dark phase
ggplot(blank_data, aes(R.umol.min, Plate.ID)) +
geom_point()
#display mean blankvalues
meanRblank<-mean(blank_data$R.umol.min) #mean R phase blanks
#filter dark phase blank values
blank_data<-blank_data%>%
filter(R.umol.min > -0.0002)
ggplot(blank_data, aes(R.umol.min, Plate.ID,)) +
geom_point()
oxygen$code<-paste(oxygen$Date, oxygen$Plate.ID)
plot(oxygen$R.umol.min~as.factor(oxygen$code), ylab="umol O2 min-1")
#blank per plate
resp.blnk <- aggregate(R.umol.min ~ Plate.ID, data=blank_data, mean) #calculate average blank per plate
colnames(resp.blnk)[colnames(resp.blnk) == 'R.umol.min'] <- 'R.Blank.umol.min' #rename to specify blank for R
oxygen <- full_join(oxygen, resp.blnk) #add R blanks to master
oxygen<-oxygen%>%
mutate(R.Blank.umol.min = ifelse(is.na(R.Blank.umol.min), meanRblank, R.Blank.umol.min))
oxygen$R.Blank.umol.min <- meanRblank
range(oxygen$R.umol.min*10000)
range(oxygen$R.Blank.umol.min*10000)
oxygen$R.umol.min.corr<-oxygen$R.umol.min-oxygen$R.Blank.umol.min #subtract R blanks
range(oxygen$R.umol.min.corr*10000)
ggplot(oxygen, aes(R.umol.min.corr, Plate.ID)) +
geom_point()
oxygen.bio <- oxygen %>% filter(Type == "Coral") #isolate only biological samples and drop unused factor levels
oxygen.bio <- droplevels(oxygen.bio) #drop unused factor levels
oxygen.bio$Size.mm2 <- as.numeric(as.character(oxygen.bio$Size.mm2))
#respiration
oxygen.bio$R.umol.mm2.min <- oxygen.bio$R.umol.min.corr/oxygen.bio$Size.mm2 #calculate oxygen per organism (larvae or recruit)
oxygen.bio$R.nmol.mm2.min <- oxygen.bio$R.umol.mm2.min*1000 #calculate nanmoles
ggplot(oxygen.bio, aes(R.nmol.mm2.min, Plate.ID)) +
geom_point()
#filter outliers
oxygen.bio <- oxygen.bio %>%
filter(R.nmol.mm2.min > -0.15) %>%
filter(R.nmol.mm2.min < 0)
ggplot(oxygen.bio, aes(R.nmol.mm2.min, Plate.ID)) +
geom_point()
ggplot(oxygen.bio, aes(R.nmol.mm2.min, Plate.ID,)) +
geom_point()
#Plot Resp as a function of Fluorescent
ggplot(data = oxygen.bio, aes(x = Fluorescent, y = R.nmol.mm2.min)) +
stat_poly_line() +
stat_poly_eq(use_label(c("eq", "R2","P")), size = 4) +
geom_point() +
theme_classic()
#Plot Resp as a function of Size
ggplot(data = oxygen.bio, aes(x = Size.mm2, y = R.nmol.mm2.min)) +
stat_poly_line() +
stat_poly_eq(use_label(c("eq", "R2","P")), size = 4) +
geom_point() +
theme_classic()
#Plot Resp as a function of Size
ggplot(data = oxygen.bio, aes(x = log10(Size.mm2+1), y = log10(R.nmol.mm2.min+1))) +
stat_poly_line() +
stat_poly_eq(use_label(c("eq", "R2","P")), size = 4) +
geom_point() +
theme_classic()
write.csv(oxygen.bio, paste0("/Users/talimass/Documents/Documents - MacBook Pro/GitHub/BSF_Climate_Solutions/Ranalysis/output/Liel_spat_RespRates.csv", sep="")) #save final file
